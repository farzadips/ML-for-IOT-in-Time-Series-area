{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import argparse\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow.lite as tflite\r\n",
    "from tensorflow import keras\r\n",
    "import zlib\r\n",
    "from platform import python_version\r\n",
    "import tensorflow_model_optimization as tfmot   \r\n",
    "import tempfile\r\n",
    "print(f\"Python version used to excute the code is {python_version()}\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python version used to excute the code is 3.9.7\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from classes import read_audios\r\n",
    "from classes import SignalGenerator\r\n",
    "from classes import make_models\r\n",
    "from classes import model_analysis\r\n",
    "from classes import latency"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "version = \"a\"\r\n",
    "m = \"cnn\"   # model name [ mlp , cnn , ds_cnn  ]\r\n",
    "mfcc = True    # True --> excute mfcc , False --> excute STFT\r\n",
    "alpha = 0.3    # The width multiplier used to apply the structured Pruning \r\n",
    "epochs = 1\r\n",
    "\r\n",
    "model_version = f\"_V_{version}_alpha={alpha}\"\r\n",
    "mymodel = m + model_version\r\n",
    "TFLITE =  f'{mymodel}.tflite'     # path for saving the best model after converted to TF.lite model \r\n",
    "units = 8                         # The number of output class [8:without silence , 9 : with silence]\r\n",
    "################## Fix the Random seed to reproduce the same results \r\n",
    "seed = 42\r\n",
    "tf.random.set_seed(seed)\r\n",
    "np.random.seed(seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "reading_class = read_audios('I:\\Polito\\ML4IOT\\CODES TO DO\\Lab3\\ex2\\data\\mini_speech_commands')\r\n",
    "train_files, val_files, test_files = reading_class.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "number_of_bins = [30,40]\r\n",
    "lower_freq = [1000,2000]\r\n",
    "upper_freq = [3000,4000]\r\n",
    "sample_rate = [8000,16000]\r\n",
    "df = pd.DataFrame(columns=['number_of_bins', 'lower_freq', 'upper_freq','sample_rate','acuracy','size','latency'])\r\n",
    "for p1 in range(len(number_of_bins)):\r\n",
    "    for p2 in range(len(lower_freq)):\r\n",
    "        for p3 in range(len(upper_freq)):\r\n",
    "            for p4 in range(len(sample_rate)):\r\n",
    "                if((lower_freq[p2] < upper_freq[p3]) and (upper_freq[p3] <= sample_rate[p4]/2)):\r\n",
    "                    data = [[number_of_bins[p1],lower_freq[p2],upper_freq[p3],sample_rate[p4],0,0]]\r\n",
    "                    d = pd.DataFrame(data, columns=['number_of_bins', 'lower_freq', 'upper_freq','sample_rate','acuracy','size','latency'])\r\n",
    "                    df = df.append(d, ignore_index = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "LABELS = np.array(['stop', 'up', 'yes', 'right', 'left', 'no',  'down', 'go'] , dtype = str) \r\n",
    "\r\n",
    "STFT_OPTIONS = {'frame_length': 256, 'frame_step': 128, 'mfcc': False}\r\n",
    "MFCC_OPTIONS = {'frame_length': 640, 'frame_step': 320, 'mfcc': True,\r\n",
    "        'lower_frequency': 20, 'upper_frequency': 4000, 'num_mel_bins': 40,\r\n",
    "        'num_coefficients': 10, 'sampling_rate': 16000}\r\n",
    "if mfcc is True:\r\n",
    "    options = MFCC_OPTIONS\r\n",
    "    strides = [2, 1]\r\n",
    "else:\r\n",
    "    options = STFT_OPTIONS\r\n",
    "    strides = [2, 2]\r\n",
    "\r\n",
    "generator = SignalGenerator(LABELS, **options)\r\n",
    "train_ds = generator.make_dataset(train_files, True)\r\n",
    "val_ds = generator.make_dataset(val_files, False)\r\n",
    "test_ds = generator.make_dataset(test_files, False)\r\n",
    "\r\n",
    "model_maker = make_models()\r\n",
    "\r\n",
    "############ Applying Structured-Based Pruning\r\n",
    "model, model_checkpoint_callback, checkpoint_filepath = model_maker.models(alpha, strides, units, model_version, mfcc, mymodel,False,train_ds)\r\n",
    "\r\n",
    "############ Applying Magnitude-Based Pruning\r\n",
    "#model, model_checkpoint_callback, checkpoint_filepath = model_maker.models(1, strides, units, model_version, mfcc, mymodel)\r\n",
    "\r\n",
    "history = model.fit(train_ds, epochs=epochs,   validation_data=val_ds,callbacks=[model_checkpoint_callback ])\r\n",
    "model_maker.plot_loss(history, mymodel)\r\n",
    "\r\n",
    "analysis = model_analysis(test_ds, checkpoint_filepath, train_ds)\r\n",
    "Compressed , tflite_model_dir = analysis.S_pruning_Model_evaluate_and_compress_to_TFlite( tflite_model_dir = TFLITE)\r\n",
    "\r\n",
    "acc, size = analysis.load_and_evaluation(tflite_model_dir, Compressed)\r\n",
    "\r\n",
    "laten = latency()\r\n",
    "inf, tot = laten.calculate(model = tflite_model_dir, mfcc = True ,rate = 16000, lower_frequency = 20, upper_frequency = 4000, num_mel_bins = 40)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "%run kws_latency.py --model ./models/cnn_V_a_alpha=0.3.tflite --mfcc --rate 16000 --lower-frequency 20 --upper-frequency 4000 --bins 40"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference Latency 2.67ms\n",
      "Total Latency 72.43ms\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "laten = latency()\r\n",
    "inf, tot = laten.calculate(model = './models/cnn_V_a_alpha=0.3.tflite', mfcc = True ,rate = 16000, lower_frequency = 20, upper_frequency = 4000, num_mel_bins = 40)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference Latency 2.09ms\n",
      "Total Latency 55.03ms\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Compressed , Quantized   = analysis.apply_Quantization(TFLITE, PQT=True , WAPQT = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the model is saved successfuly to ./models/PQT_cnn_V_a_alpha=0.3.tflite\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "analysis.load_and_evaluation(Quantized , Compressed)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "************************************************** \n",
      " The Size of TF lite model  Before compression is = 32.992 kb\n",
      "************************************************** \n",
      " The Size of TF lite model  After compression is = 28.237 kb\n",
      "************************************************** \n",
      " The accuracy of TF lite model is = 69.62 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "WA_Compressed , WA_Quantized   = analysis.apply_Quantization(TFLITE, PQT=False ,WAPQT=True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fb545cee0f5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mWA_Compressed\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mWA_Quantized\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_Quantization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTFLITE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPQT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mWAPQT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Github\\Machine-learning-for-IOT\\Homework2\\new ex2\\classes.py\u001b[0m in \u001b[0;36mapply_Quantization\u001b[1;34m(self, tflite_model_dir, PQT, WAPQT)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepresentative_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepresentative_dataset_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mtflite_model_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"WAPQT_{tflite_model_dir}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\env_ML4IOt\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \"\"\"\n\u001b[1;32m-> 1076\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTFLiteConverterV2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\env_ML4IOt\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m     return super(TFLiteFrozenGraphConverterV2,\n\u001b[1;32m--> 900\u001b[1;33m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\env_ML4IOt\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m    636\u001b[0m         self.inference_input_type, self.inference_output_type)\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcalibrate_and_quantize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calibrate_quantize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_sparsify_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\env_ML4IOt\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m_calibrate_quantize_model\u001b[1;34m(self, result, inference_input_type, inference_output_type, activations_type, allow_float)\u001b[0m\n\u001b[0;32m    450\u001b[0m       return calibrate_quantize.calibrate_and_quantize(\n\u001b[0;32m    451\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepresentative_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_input_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m           inference_output_type, allow_float, activations_type)\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_is_unknown_shapes_allowed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\env_ML4IOt\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py\u001b[0m in \u001b[0;36mcalibrate_and_quantize\u001b[1;34m(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m     86\u001b[0m     \u001b[0minitialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minitialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0minitialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not callable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "analysis.load_and_evaluation(WA_Quantized , WA_Compressed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad4a7f633457edeca986db117c49439398b3575b7cfc8b89bb9541a12d05f016"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}